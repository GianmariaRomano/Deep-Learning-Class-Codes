{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dd51230-f46b-4b21-abfa-acfc195f5e85",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d92940-4a71-436a-bdfe-1e755879560b",
   "metadata": {},
   "source": [
    "To overcome the limitations of linear regression, a multilayer perceptron adds a hidden layer that first processes the input matrix by means of a (non-linear) activation function and then feeds the output of the hidden layer to the output layer, which will perform the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c892099b-1e1d-4ff9-9656-2044d1441bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install d2l==1.0.0a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f26c044-c50d-4139-85ac-445b91edcf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48e727e-94ec-4507-bbe9-fae21090879a",
   "metadata": {},
   "source": [
    "Start by creating a multilayer perceptron by defining its weights and activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9926ca68-9d2b-4301-a45e-46183c14868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPScratch(d2l.Classifier):\n",
    "    def __init__(self, num_inputs, num_outputs, num_hiddens, lr, sigma=0.01):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.W1 = nn.Parameter(torch.randn(num_inputs, num_hiddens) * sigma)\n",
    "        self.b1 = nn.Parameter(torch.zeros(num_hiddens))\n",
    "        self.W2 = nn.Parameter(torch.randn(num_hiddens, num_outputs) * sigma)\n",
    "        self.b2 = nn.Parameter(torch.zeros(num_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20854c1e-cf92-490f-a183-03411e7da1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    a = torch.zeros_like(X)\n",
    "    return torch.max(X, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae533318-6af5-4169-a026-b51c07ded735",
   "metadata": {},
   "source": [
    "Add the feedforward functions to the multilayer perceptron. <br>\n",
    "The PyTorch framework already implements the backward pass by symbolic autodifferentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceb4cb9-d0f7-4934-88ab-b9bf455baa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(MLPScratch)\n",
    "def forward(self, X):\n",
    "    X = X.reshape((-1, self.num_inputs))\n",
    "    H = relu(torch.matmul(X, self.W1) + self.b1)\n",
    "    return torch.matmul(H, self.W2) + self.b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff4ccc-5170-4a39-84ed-8d78e8c3741c",
   "metadata": {},
   "source": [
    "Train the model on the MNIST Fashion dataset. <br>\n",
    "Generally speaking, the training step provides a trend of the training loss, which represents the errors associated to the training procedure, and the validation step, which represents the errors associated to hyperparameter tuning. <br>\n",
    "A model is said to \"overfit\" the data if it does very well on the training dataset but cannot generalize for unseen testing inputs: whenever this happens, the training loss decreases but the validation step stays constant. <br>\n",
    "On the other hand, a model is said to \"underfit\" the data if too much importance is given to the regularization: whenever this happens, the validation loss decreases but the training loss stays constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffd2c4d-5c2a-46ca-92e9-9e0e93231a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPScratch(num_inputs=784, num_outputs=10, num_hiddens=256, lr=0.1)\n",
    "data = d2l.FashionMNIST(batch_size=256)\n",
    "trainer = d2l.Trainer(max_epochs=10)\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380f58e4-995f-48c4-91b6-f6ef426d2d21",
   "metadata": {},
   "source": [
    "When working with images, convolutional neural networks are more convenient to implement compared to multilayer perceptrons. <br>\n",
    "Generally speaking, a convolutional neural network takes an input image and, at the convolutional layer, convolves it with a (small) kernel in order to produce an activation map containing the extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8233a3e-fb44-4e1b-b49e-eeb3ce2b5407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):  #@save\n",
    "    # This function computes 2D convolution between the input image X and the kernel K.\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e02db1-f33e-4948-8b2e-9ffccb1c4139",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]]) # Input tensor.\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]]) # Kernel tensor.\n",
    "corr2d(X, K) # Activation map obtained by applying convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1c33c1-fd1f-4990-86e7-c649eb0d3bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9ffb3c-fa8f-4bf7-bea9-76cf2a991109",
   "metadata": {},
   "source": [
    "A simple application of 2D convolution consists in edge detection, which is computed using the first derivative of the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96b1917-0f0d-49d6-af10-2a7d88909085",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.ones((6, 8))\n",
    "X[:, 2:6] = 0\n",
    "X\n",
    "\n",
    "K = torch.tensor([[1.0, -1.0]])\n",
    "\n",
    "Y = corr2d(X, K)\n",
    "Y\n",
    "\n",
    "# Try to perform the convolution on the transposed image.\n",
    "corr2d(X.t(), K) # Since K only detects vertical edges, nothing will be detected on the transposed image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365b170d-2592-4d73-a27c-04c5eba21313",
   "metadata": {},
   "source": [
    "Now, try to learn the kernel that generates a filtered image from a given input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fad62fd-dcfa-408d-91d4-caa8cca38dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a two-dimensional convolutional layer with 1 output channel and a kernel of shape 1x2 (ignore the bias).\n",
    "conv2d = nn.LazyConv2d(1, kernel_size=(1, 2), bias=False)\n",
    "\n",
    "# The two-dimensional convolutional layer uses four-dimensional input and output in the format of (example, channel, height, width), where the batch size (number of examples in the batch) and the number of channels are both 1.\n",
    "X = X.reshape((1, 1, 6, 8))\n",
    "Y = Y.reshape((1, 1, 6, 7))\n",
    "lr = 3e-2  # Learning rate for optimization.\n",
    "\n",
    "for i in range(10):\n",
    "    Y_hat = conv2d(X)\n",
    "    l = (Y_hat - Y) ** 2\n",
    "    conv2d.zero_grad()\n",
    "    l.sum().backward()\n",
    "    # Update the kernel.\n",
    "    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n",
    "    if (i + 1) % 2 == 0:\n",
    "        print(f'epoch {i + 1}, loss {l.sum():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0465a3c6-a8d9-437f-865e-8df088da5097",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d.weight.data.reshape((1, 2)) # Update the kernel using the learned values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116c3ce2-e221-4c41-8f93-76f8da8ebe62",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08fe3c4-5861-4059-b665-7123679c7b99",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Create an image with diagonal edges.\n",
    "1. Apply the edge detection kernel to the image.\n",
    "2. What happens when the image is transposed?\n",
    "3. What happens when the kernel is transposed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079ee423-3fc4-48a3-a205-1777f0c9e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by creating an input image.\n",
    "X = torch.eyes(8) # Identity tensor of size 8x8.\n",
    "\n",
    "# Now, define the edge detection kernel.\n",
    "K_1 = torch.tensor([[0.0, -1.0], [1.0, 0.0]) # Filter to detect the main diagonal.\n",
    "K_2 = torch.tensor([[0.0, 1.0], [-1.0, 0.0]) # Filter to detect the anti-diagonal.\n",
    "\n",
    "# Now, apply convolution to find the edges.\n",
    "corr2d(X, K_1)\n",
    "# corr2d(X, K_2)\n",
    "\n",
    "# Now, try to transpose X.\n",
    "corr2d(X.t(), K_1)\n",
    "# corr2d(X.t(), K_2)\n",
    "\n",
    "# Lastly, try to transpose K.\n",
    "corr2d(X, K_1.t())\n",
    "# corr2d(X, K_2.t())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
